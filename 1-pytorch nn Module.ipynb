{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part, I'll be trying to understand the design and implementation behind the pytorch nn.Module and how it ties in with fastai. In this section, I will be exploring basic neural net ops and how the pytorch modelling works. The dataset I am using is the KMNIST dataset which can be found [here](https://github.com/rois-codh/kmnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor, from_numpy, flatten\n",
    "import operator\n",
    "from functools import partial\n",
    "from torchvision import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1 passed\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "eq,\n1.1,\n1.2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41299803114d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test 1 passed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-41299803114d>\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{condition.__name__},\\n{a},\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-41299803114d>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, condition)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{condition.__name__},\\n{a},\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: eq,\n1.1,\n1.2"
     ]
    }
   ],
   "source": [
    "def test(a, b, condition):\n",
    "    assert condition(a, b), f\"{condition.__name__},\\n{a},\\n{b}\"\n",
    "def test_eq(a,b):\n",
    "    test(a, b, operator.eq)\n",
    "    \n",
    "test_eq(1,1)\n",
    "print(\"test 1 passed\")\n",
    "test_eq(1.1,1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/media/wwymak/Storage/kmnist\")\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist = datasets.KMNIST(data_dir, download=True)\n",
    "kmnist_test = datasets.KMNIST(data_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'ki', 'su', 'tsu', 'na', 'ha', 'ma', 'ya', 're', 'wo']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmnist.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(kmnist), len(kmnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = kmnist.data\n",
    "y_train = kmnist.targets\n",
    "X_test =  kmnist_test.data\n",
    "y_test = kmnist_test.targets\n",
    "\n",
    "X_train = X_train.view(-1, 28*28)\n",
    "X_test = X_test.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([10000, 784]) torch.Size([60000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "assert X_train.max() <=255\n",
    "assert X_train.min() >= 0\n",
    "test_eq(y_train.max(), 9)\n",
    "test_eq(y_train.min(), 0)\n",
    "\n",
    "test_eq(y_test.max(), 9)\n",
    "test_eq(y_test.min(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a61131518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = X_train[8]\n",
    "plt.imshow(img.view(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the mapping between the class labels (0-9) and the actual characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_mapping =pd.read_csv(\"/Users/wwymak/computer-science-courses/kmnist/kmnist_classmap.csv\")\n",
    "# char_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model\n",
    "A very simple set of weights/biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first dimension is just one image flattened into one row of 728 numbers\n",
    "# 10 is for the number of classes\n",
    "weights = torch.rand(28*28, 10).float()\n",
    "bias = torch.zeros(10).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication diversion\n",
    "we can think of a neural network as a set of matrix multiplications e.g W.x + b etc, so derive that first. In it's simplest form a matrix multiplication is multiple row i by col j and sum them up for the value in `M[i, j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    a_rows, a_cols = a.shape\n",
    "    b_rows, b_cols = b.shape\n",
    "    \n",
    "    assert a_cols == b_rows\n",
    "    \n",
    "    c = torch.zeros(a_rows, b_cols)\n",
    "    for i in range(a_rows):\n",
    "        for j in range(b_cols):\n",
    "            for k in range(a_cols):\n",
    "                c[i,j] += a[i, k] * b[k, j]\n",
    "                \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = X_test[:5]\n",
    "b = weights\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 523 ms, sys: 0 ns, total: 523 ms\n",
      "Wall time: 522 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1 = matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]),\n",
       " tensor([[19184.1680, 18895.9844, 19424.8691, 18792.7246, 19044.3848, 19114.2676,\n",
       "          19067.0488, 19938.3418, 19600.9180, 19152.0176],\n",
       "         [20923.6699, 19726.8398, 20753.5938, 21424.0000, 19281.7383, 19815.1523,\n",
       "          19750.2324, 21220.1660, 19970.5156, 21931.5391],\n",
       "         [19158.7031, 17457.3691, 18624.7402, 19292.1484, 18284.0723, 17722.7129,\n",
       "          17361.8535, 18526.9375, 17673.6309, 18021.5176],\n",
       "         [24860.8691, 21991.3555, 23012.1191, 23432.3496, 23545.5488, 23852.4395,\n",
       "          25373.2012, 23591.1914, 22907.3691, 23029.5488],\n",
       "         [24621.1777, 24567.4160, 26311.2246, 26570.6152, 28151.0762, 25776.7031,\n",
       "          26807.6680, 25627.1445, 25339.7266, 26401.3047]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape, t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using native python is very slow. To speed it up, get rid of the for loops one by one with pytorch broadcasting/vectorised ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elementwise ops\n",
    "In pytorch/np etc vectors, you can replace a whole col/row with `:` if you want to do elementwise ops across the whole thing. The above can be written as :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul2(a, b):\n",
    "    a_rows, a_cols = a.shape\n",
    "    b_rows, b_cols = b.shape\n",
    "    \n",
    "    assert a_cols == b_rows\n",
    "    \n",
    "    c = torch.zeros(a_rows, b_cols)\n",
    "    for i in range(a_rows):\n",
    "        for j in range(b_cols):\n",
    "            c[i,j] = (a[i, :] * b[:, j]).sum()\n",
    "                \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 ms, sys: 91 µs, total: 1.32 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "a = a.type(torch.FloatTensor)\n",
    "b = b.type(torch.FloatTensor)\n",
    "%time t2 = matmul2(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_eq(a,b):\n",
    "    return torch.allclose(a, b,rtol=1e-3, atol=1e-5 )\n",
    "def test_near(a,b):\n",
    "    test(a, b,approx_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed up with broadcasting\n",
    "\n",
    "In broadcasting, dimensions are compared elementwise and if one of them is one then it's expanded to match the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a few characters to see what they look like before procedding further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul3(a, b):\n",
    "    a_rows, a_cols = a.shape\n",
    "    b_rows, b_cols = b.shape\n",
    "    \n",
    "    assert a_cols == b_rows\n",
    "    \n",
    "    c = torch.zeros(a_rows, b_cols)\n",
    "    for i in range(a_rows):\n",
    "        c[i] = (a[i][...,None] * b).sum(dim=0)\n",
    "                \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 µs ± 251 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t3 = matmul3(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.81 µs ± 44.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# native pytorch:\n",
    "%timeit t4 = a.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.4 µs ± 8.67 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "m3,m4  = a.cuda(),b.cuda()\n",
    "%timeit t5 = m3.matmul(m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_rand_int(low, high):\n",
    "    \"\"\"\n",
    "    generate a random int between min and max using pytorch native funcs\n",
    "    \"\"\"\n",
    "    return torch.randint(low, high, size=(1,)).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "for i in range(1, 4):\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    random_sample = pytorch_rand_int(0, X_train.size()[0])\n",
    "    ax.imshow(X_train[random_sample].view(28, 28), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also want to normalise the data so e.g. illumniation does affect the output of the training/prediction. In normalistaion we rescale the samples so they have mean 0 and standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x, mean, std):\n",
    "    return (x - mean) /std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(48.9312), tensor(88.8274))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's normalise our train/test tensors. Note, we have to use the _train_ mean/std for the test set otherwise the network might be predicting on data that looks very different to the training set if e.g. the test set all have a much higher intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalise(X_train, train_mean, train_std)\n",
    "X_test = normalise(X_test, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we recalculate the mean/std we should see them to be approx mean = 0, std = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0003), tensor(1.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can define a test for whether the number is more or less what we expect (due to computation, its usually never exactly 0.000 to an infinite amount of zeros..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near_zero(a, tolerance = 1e-3):\n",
    "    assert a.abs() < tolerance, f\"{a} not near zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(train_mean)\n",
    "test_near_zero(1 - train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the dimensions of our tensors -- these should be `X_train = [60000, 784]` (we have 60k training samples) and `nclasses = 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784, tensor(10.))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = X_train.shape\n",
    "nclasses = y_train.max() + 1\n",
    "\n",
    "n, m, nclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's define a simple fully connected neural net with 1 hidden layer.  as per neural net definition, each layer is just a matrix multiplication of `W . x + b` for weight matrix `W` and bias `b`. In this most basic version, we will use MSE as the metric (ie the network acts as a regressor rather than the 'normal' classification.\n",
    "\n",
    "In the neural net training, we would ideally keep the mean/std of the result of each layer to be 0/1. This is to help the net train-- if the mean/std keeps on decreasing over the layers we get a vanishing gradient on backpropagation and if it keeps incresasing then we get to infinity very quickly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in the hidden layer:\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by the rules of matrix multiplication, to get to nh hidden layers  W1 will have to be of shape (m, nh), and b1 shape nh, W2 have shape (nh, 1), b2 shape(1)\n",
    "\n",
    "Let's init the weight and biases. W1, W2, b1, and b2 are learned params, so they can be random -- b1 and b2 are zero since they are just additive const, but W1 and W2 can't be zero-- if they are, the whole network collapses, so init them with random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sqrt(m) is the normalisation const for simplified version of kaiming init\n",
    "W1 = torch.randn(m, nh) / math.sqrt(m)\n",
    "W2 = torch.randn(nh, 1)/  math.sqrt(m)\n",
    "\n",
    "b1 = torch.zeros(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's check that we still get the desired mean = 0, std = 1 behavior with these random weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0003), tensor(1.))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that our train has mean and std of 0, 1\n",
    "X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An operation through 1 layer neural net can be thought of as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(X, w, b): \n",
    "    \"\"\"\n",
    "    X, w are tensors, b the bias vector. X@w is the matmul\n",
    "    \"\"\"\n",
    "    return X@w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run X_test through the above layer, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0274), tensor(1.0044))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lin(X_test.float(), W1.float(), b1.float())\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the non linearity in the neral net, there is usually an activation function. One of the most common types of activation in neural nets is the relu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4020), tensor(0.5866))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply reul to t:\n",
    "t = relu(t)\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and std are no longer near 0/ 1. This is because of the relu, in which we lost half of the input (anything -ve is zero). So the 'proper' init for relu is to take away a 0.5. As we can see, we're back in action with mean approx zero and std closer to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0178), tensor(0.7813))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def general_relu(x, offset=-0.5):\n",
    "    return x.clamp_min(0.) - 0.5\n",
    "\n",
    "W1 = torch.randn(m,nh)*math.sqrt(2/m)\n",
    "t = general_relu(lin(X_test.float(), W1.float(), b1.float()))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaiming init method is implemented in Pytorch as [`torch.nn.init.kaiming_normal_`](https://github.com/pytorch/pytorch/blob/8868a4f20be52704df23d96bda8f600d349a6b9f/torch/nn/init.py#L295) / [`torch.nn.init.kaiming_uniform_`](https://github.com/pytorch/pytorch/blob/8868a4f20be52704df23d96bda8f600d349a6b9f/torch/nn/init.py#L260) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0646), tensor(0.8102))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = torch.randn(m,nh)\n",
    "init.kaiming_normal_(W1, mode='fan_out')\n",
    "t = general_relu(lin(X_test.float(), W1.float(), b1.float()))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers as classes\n",
    "\n",
    "Pytorch is fairly strongly OOP and we can define each layer as a class that we can resue. Each layer should have a forward pass method to calculate the loss and a backward pass for backpropagation.\n",
    "\n",
    "To make sense of the backward pass gradient calculations, we have to remember the chain rule in differentiation. \n",
    "\n",
    "e.g if the network has 3 layers, with `h -> g -> f`, the input `x` is transformed by `L = f(g(h(x)))`. \n",
    "\n",
    "So in backprop: `dL/dx = df/dg * dg/dh * dh/dx`. Thinking in terms of layers, if we take the middle layer as an example, the total gradient after backprop through that layer is `df/dg (out.grad)` multiplied by the `dg/dh` (current grad)\n",
    "\n",
    "A much more detailed explanation of backpropagation can be found from [cs231n](http://cs231n.github.io/optimization-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized grads intuitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "x = torch.tensor([[1., 2.], [4., 5.]])\n",
    "b = torch.tensor([[1.], [1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the shapes of these tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9., 12., 15.],\n",
       "        [24., 33., 42.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 13., 16.],\n",
       "        [25., 34., 43.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@W1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x@W1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a non tensor eq: `y = Wx + b`, `dy/dx = W`. However, if W and x are tensors it's a bit of a different story, and you have to be careful about the transpose. In the above example, the input has shape(2,2), and the output shape(2,3). the input gradient should have the same shape as the input, (2,2), and the grad of the output shape (2,3) \n",
    "which means  for `out_grad@W1` to work, W1 has to have shape(3,2), ie transpose of W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer defs\n",
    "We can define each common layer e.g. Relu/Linear as a class. By overriding the python `__call__` dunder method we can use a class like a function def e.g. `Relu(x)`. In each of the classes, we would like to do the backward propagation, which would update the input_grad with `grad_of_layer * grad_output_tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.) - 0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "#         relu has grad = 1 for x > 0 and 0 otherwise\n",
    "        self.inp.g = ( self.inp >0).float() * self.out.g \n",
    "    \n",
    "class Linear():\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp@self.w + self.b\n",
    "        return self.out\n",
    "        \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g@self.w.t()\n",
    "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "        \n",
    "class MSE():\n",
    "    def __call__(self, inp, target):\n",
    "        self.inp = inp\n",
    "        self.target = target\n",
    "        #mean squared error\n",
    "        self.out = (inp.squeeze() - self.target).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        # grad = 2 / n * (inp - target)\n",
    "        self.inp.g = 2. / self.target.shape[0] * (self.inp.squeeze() - self.target).unsqueeze(-1)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Linear(w1, b1), Relu(), Linear(w2, b2)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def __call__(self, x, target):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x, target)\n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grad property for all the tensors\n",
    "W1.g, b1.g, W2.g, b2.g = [None] * 4\n",
    "model = Model(W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 10.3 ms, total: 255 ms\n",
      "Wall time: 96.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.5553)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 26.8 s, total: 37 s\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0249,  0.0350,  0.0115,  ..., -0.0283,  0.1063, -0.0074],\n",
       "        [-0.0247,  0.0347,  0.0114,  ..., -0.0281,  0.1049, -0.0073],\n",
       "        [-0.0244,  0.0343,  0.0112,  ..., -0.0277,  0.1029, -0.0072],\n",
       "        ...,\n",
       "        [-0.0242,  0.0318,  0.0105,  ..., -0.0262,  0.0967, -0.0066],\n",
       "        [-0.0246,  0.0337,  0.0109,  ..., -0.0271,  0.1007, -0.0071],\n",
       "        [-0.0250,  0.0349,  0.0113,  ..., -0.0281,  0.1049, -0.0073]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each layer has the forward and backward methods, we can define a Module class with the forward and backward methods and have the layers inherit from it. \n",
    "\n",
    "In pytorch, this is the `nn.Module` class, which all layers etc in pytorch inherit. The linear, relu layers we defined above are also in pytorch (not the generalised relu though)\n",
    "\n",
    "In nn.Module, the forward method is not defined by default, but our model does not need to define it if we're not using it, e.g. in the following the forward is done by the layers not the model so we don't need to implement the `forward` in the `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model redefined to inherit from nn.Module\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "        self.loss = nn.MSELoss()\n",
    "    def __call__(self, x, target):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x.squeeze(), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 12.6 ms, total: 228 ms\n",
      "Wall time: 130 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 184 ms, sys: 8.47 ms, total: 192 ms\n",
      "Wall time: 86.1 ms\n"
     ]
    }
   ],
   "source": [
    "#  in pytorch the backward is called from the loss which dloss/dx for every parameter x which has requires_grad=True\n",
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
